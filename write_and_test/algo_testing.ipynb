{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f024cc-c360-4336-890e-37a9fadbbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import proplot\n",
    "import torch\n",
    "import random\n",
    "%run ../r2d2_algo/r2d2_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02debcf3-e33b-439e-af07-642fff9bd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=1, batch_size=256, buffer_size=20000,\n",
    "                 burn_in_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f369752d-5810-45af-a90e-afd4b0be00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode length 193.8, mean return 0.2\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n"
     ]
    }
   ],
   "source": [
    "agent.collect(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd46a2c2-c241-4b09-ab43-c9f25872f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c7c4a93-f413-4e84-85f6-18646f15198c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 True\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0.0 False\n",
      "0 False\n",
      "0 False\n",
      "0 True\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n",
      "0 False\n"
     ]
    }
   ],
   "source": [
    "'''Run steps manually'''\n",
    "\n",
    "obs = agent.env.reset()\n",
    "rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "for i in range(500):\n",
    "    action, q_values, next_rnn_hxs = agent.act(obs, rnn_hxs)\n",
    "    next_obs, reward, done, info = agent.env.step(action.item())\n",
    "    \n",
    "    if reward == 1:\n",
    "        break\n",
    "        \n",
    "    if done:\n",
    "        next_obs = agent.env.reset()\n",
    "        next_rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "    \n",
    "    obs = next_obs\n",
    "    rnn_hxs = next_rnn_hxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d1ce7-4394-40e9-a41a-53c4f151f023",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optimizing batch calls for ResettingGRU\n",
    "\n",
    "Running three 1 row GRU calls takes about as much time as 1 batched 64 GRU call. \n",
    "\n",
    "Padding adds linearly more time as well. To optimize then, it makes sense to batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbf829-b94f-4c70-b7af-6e9b64a456b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Testing times to finish forward calls adding rows or sequence length steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "522eb73b-e32c-46a1-98b5-5640da7a76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = R2D2Agent()\n",
    "agent.train(1)\n",
    "data = agent.rb.sample(64)\n",
    "\n",
    "obs = data['observations']\n",
    "dones = data['dones']\n",
    "rnn_hxs = data['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b85ac120-2485-45a1-ae41-a63eb991d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd5e3eae-ef35-4eb9-8426-0b0868b4dfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94 ms ± 28.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(obs, rnn_hxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "944285e7-6b54-4de7-8d81-7f3d356d641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9 ms ± 59.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(obs[:-1], rnn_hxs[:, :-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b2b2a3d-aedd-4b29-a7d9-69b07eefd87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.64 ms ± 74.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(obs[:, :-1, :], rnn_hxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6f598f9-ac1b-4df7-be94-bd590b9bbb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.11 ms ± 140 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(torch.concat([obs, obs], dim=1), rnn_hxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e792ab07-ecfc-4121-b5e1-5671a68af258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.16 ms ± 109 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(torch.concat([obs[:-1], obs[:-1]], dim=1), rnn_hxs[:, :-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e58a2db6-e543-41b2-b489-3be16e34bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 231 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(torch.concat([obs]*4, dim=1), rnn_hxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f53de2da-8511-4bb0-872f-761cac42eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 ms ± 187 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(torch.concat([obs[:-1]]*4, dim=1), rnn_hxs[:, :-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bab2c58-99aa-43c0-97a6-0de27da324a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12, 4])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00b191f7-f97c-4f42-a3dd-438a97f4057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 µs ± 8.53 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(obs[:1, :4, :], rnn_hxs[:, :1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c5fe90f-4873-49c7-a413-744c2678eb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 µs ± 916 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(obs[:1, :1, :], rnn_hxs[:, :1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927be1a-692e-4318-9988-f05e52338faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d336a663-118f-4f02-afa6-21c83dd32021",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = torch.zeros((64, 12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "18dc5e8d-5e74-45e3-887a-98105dd004a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5 µs ± 191 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "empty[:, 4:8, :] = obs[:, 4:8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "da120e40-d0e1-454f-bf4b-73701b47260d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178a6bd-ef2a-4286-92e5-f235b97674f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing rebatched ResettingGRU, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "b722f1a2-aacd-4e38-9f2f-25f54255e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResettingGRU2(nn.Module):\n",
    "    '''\n",
    "    Modification to GRU that can take dones on the forward call to tell when\n",
    "    state in the middle of a batched sequence forward call should be reset\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(**kwargs)\n",
    "        \n",
    "        self.hidden_size = self.gru.hidden_size\n",
    "        self.batch_first = self.gru.batch_first\n",
    "        \n",
    "    def get_rnn_hxs(self, num_batches=1):\n",
    "        '''\n",
    "        Get torch.zeros hidden states to start off with\n",
    "        '''\n",
    "        if num_batches == 1:\n",
    "            return torch.zeros(1, self.hidden_size)\n",
    "        else:\n",
    "            return torch.zeros(1, num_batches, self.hidden_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, hidden_state, dones=None):\n",
    "        if dones == None:\n",
    "            return self.gru(x, hidden_state)\n",
    "        \n",
    "        #Unfortunately need to split up the batch here\n",
    "        if self.batch_first == False:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if hidden_state.dim() == 2:\n",
    "            hidden_state = hidden_state.unsqueeze(0)\n",
    "            x = x.unsqueeze(0)\n",
    "            dones = dones.unsqueeze(0)\n",
    "\n",
    "        num_batches = hidden_state.shape[1]\n",
    "\n",
    "        #Generate a new padded x and rnn_hxs vector to batch forward pass\n",
    "        padded_x = torch.zeros((num_batches + extra_rows, x.shape[1], x.shape[2]))\n",
    "        padded_rnn_hxs = torch.zeros((hidden_state.shape[0], num_batches + extra_rows, hidden_state.shape[2]))\n",
    "\n",
    "        batchable_rows = (dones == 0).all(dim=1)\n",
    "        num_batchable_rows = batchable_rows.sum().item()\n",
    "        individual_rows = (~batchable_rows).argwhere().reshape(-1)\n",
    "\n",
    "        #First N rows will be taken from rows with no dones\n",
    "        padded_x[:num_batchable_rows] = x[batchable_rows]\n",
    "        padded_rnn_hxs[:, :num_batchable_rows, :] = hidden_state[:, batchable_rows, :]\n",
    "\n",
    "        #Remaining rows will be filled out in order of rows with dones\n",
    "        cur_row_idx = num_batchable_rows\n",
    "        for i in individual_rows:\n",
    "            breakpoints = (dones[i] == 1).argwhere()\n",
    "            cur_idx = 0\n",
    "            rnn_hx = hidden_state[:, i, :]\n",
    "\n",
    "            for breakpoint in breakpoints:\n",
    "                if breakpoint == 0:\n",
    "                    rnn_hx = get_rnn_hxs()\n",
    "                    continue\n",
    "                padded_x[cur_row_idx, :breakpoint-cur_idx, :] = x[i, cur_idx:breakpoint, :]\n",
    "                padded_rnn_hxs[:, cur_row_idx, :] = rnn_hx\n",
    "\n",
    "                rnn_hx = get_rnn_hxs()\n",
    "                cur_idx = breakpoint\n",
    "                cur_row_idx += 1\n",
    "\n",
    "            if cur_idx < len(dones[i]):\n",
    "                padded_x[cur_row_idx, :len(dones[i])-cur_idx, :] = x[i, cur_idx:, :]\n",
    "                padded_rnn_hxs[:, cur_row_idx, :] = rnn_hx\n",
    "                cur_row_idx += 1\n",
    "\n",
    "        #Perform forward pass on new batched\n",
    "        output, output_hx = self.gru(padded_x, padded_rnn_hxs)\n",
    "\n",
    "        #Fill out the expected output by reversing the whole process\n",
    "        full_out = torch.zeros((x.shape[0], x.shape[1], self.hidden_size))\n",
    "        full_hx_out = torch.zeros((1, x.shape[0], self.hidden_size))\n",
    "\n",
    "        full_out[batchable_rows] = output[:num_batchable_rows]\n",
    "        full_hx_out[:, batchable_rows, :] = output_hx[:, :num_batchable_rows, :]\n",
    "\n",
    "        cur_row_idx = num_batchable_rows\n",
    "        for i in individual_rows:\n",
    "            breakpoints = (dones[i] == 1).argwhere()\n",
    "            cur_idx = 0\n",
    "\n",
    "            for breakpoint in breakpoints:\n",
    "                if breakpoint == 0:\n",
    "                    continue\n",
    "                full_out[i, cur_idx:breakpoint, :] = output[cur_row_idx, :breakpoint-cur_idx, :]\n",
    "\n",
    "                cur_idx = breakpoint\n",
    "                cur_row_idx += 1\n",
    "\n",
    "            if cur_idx < len(dones[i]):\n",
    "                full_out[i, cur_idx:, :] = output[cur_row_idx, :len(dones[i])-cur_idx, :]\n",
    "                \n",
    "                print(cur_row_idx)\n",
    "                #Remember only the last rnn hidden state gets returned\n",
    "                full_hx_out[:, i, :] = output_hx[:, cur_row_idx, :]\n",
    "                cur_row_idx += 1\n",
    "            else:\n",
    "                #If we did not have remaining steps to fill, then we must have had a done\n",
    "                # on the last step, so the final rnn_hx should be zeros to return\n",
    "                full_hx_out[:, i, :] = self.get_rnn_hxs()\n",
    "\n",
    "        return full_out, full_hx_out, padded_x, padded_rnn_hxs, output, output_hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "65c7c71d-2972-4838-89f3-50698295cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResettingGRU(nn.Module):\n",
    "    '''\n",
    "    Modification to GRU that can take dones on the forward call to tell when\n",
    "    state in the middle of a batched sequence forward call should be reset\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(**kwargs)\n",
    "        \n",
    "        self.hidden_size = self.gru.hidden_size\n",
    "        self.batch_first = self.gru.batch_first\n",
    "        \n",
    "    def get_rnn_hxs(self, num_batches=1):\n",
    "        '''\n",
    "        Get torch.zeros hidden states to start off with\n",
    "        '''\n",
    "        if num_batches == 1:\n",
    "            return torch.zeros(1, self.hidden_size)\n",
    "        else:\n",
    "            return torch.zeros(1, num_batches, self.hidden_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, hidden_state, dones=None):\n",
    "        if dones == None:\n",
    "            return self.gru(x, hidden_state)\n",
    "        \n",
    "        #Unfortunately need to split up the batch here\n",
    "        if self.batch_first == False:\n",
    "            raise NotImplementedError        \n",
    "        \n",
    "        def single_gru_row(x_i, rnn_hx, done):\n",
    "            breakpoints = (done == 1).argwhere()\n",
    "            cur_idx = 0\n",
    "            output_row = torch.zeros(x_i.shape[0], self.hidden_size)\n",
    "            \n",
    "            for breakpoint in breakpoints:\n",
    "                if breakpoint == 0:\n",
    "                    rnn_hx = self.get_rnn_hxs()\n",
    "                    continue\n",
    "                out, out_hx = self.gru(x_i[cur_idx:breakpoint], rnn_hx)\n",
    "                output_row[cur_idx:breakpoint] = out\n",
    "                rnn_hx = self.get_rnn_hxs()\n",
    "                cur_idx = breakpoint\n",
    "                \n",
    "            if cur_idx < x_i.shape[0]:\n",
    "                out, out_hx = self.gru(x_i[cur_idx:], rnn_hx)\n",
    "                output_row[cur_idx:] = out\n",
    "            return output_row, out_hx\n",
    "        \n",
    "        if hidden_state.dim() == 2:\n",
    "            output, output_hx = single_gru_row(x, hidden_state, dones)\n",
    "            \n",
    "        else:\n",
    "            num_batches = hidden_state.shape[1]\n",
    "            \n",
    "            # Output will have shape [N, L, hidden_size]\n",
    "            full_out = torch.zeros((x.shape[0], x.shape[1], self.hidden_size))\n",
    "            # hidden_state output has shape [1, N, hidden_size]\n",
    "            full_hx_out = torch.zeros((1, x.shape[0], self.hidden_size))\n",
    "            \n",
    "            batchable_rows = (dones == 0).all(dim=1)\n",
    "            individual_rows = (~batchable_rows).argwhere().reshape(-1)\n",
    "            \n",
    "            # First batch all computations that have no dones in them\n",
    "            out, out_hx = self.gru(x[batchable_rows], hidden_state[:, batchable_rows, :])\n",
    "            full_out[batchable_rows] = out\n",
    "            full_hx_out[:, batchable_rows, :] = out_hx\n",
    "            \n",
    "            for i in individual_rows:\n",
    "                d = dones[i]\n",
    "                x_i = x[i]\n",
    "                rnn_hx = hidden_state[:, i, :]\n",
    "                \n",
    "                output_row, output_hx_row = single_gru_row(x_i, rnn_hx, d)\n",
    "                full_out[i] = output_row\n",
    "                full_hx_out[:, i, :] = output_hx_row\n",
    "            \n",
    "        \n",
    "        return full_out, full_hx_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fccbcbf4-7553-4d77-883b-f6acb4a5eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.11 ms ± 140 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(torch.concat([obs, obs], dim=1), rnn_hxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "faede605-a796-43cc-b971-8c8f33e645bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.16 ms ± 109 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.q_network.gru(torch.concat([obs[:-1], obs[:-1]], dim=1), rnn_hxs[:, :-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "a608049c-a744-48a5-957f-17685c6e9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru2 = ResettingGRU2(input_size=4, hidden_size=64, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "85b87349-4d16-44a1-b99f-c38c068bfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = ResettingGRU(input_size=4, hidden_size=64, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc355347-c122-4008-8922-ac78c6285e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "out1, hx1 = gru(obs, rnn_hxs, dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "6675752d-32bc-4dc9-a3d2-3ec4f9dd33d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "33\n",
      "35\n",
      "37\n",
      "39\n",
      "41\n",
      "43\n",
      "45\n",
      "47\n",
      "49\n",
      "51\n",
      "53\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "61\n",
      "64\n",
      "66\n",
      "68\n",
      "70\n",
      "72\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "84\n",
      "85\n",
      "87\n",
      "89\n",
      "91\n",
      "93\n",
      "95\n",
      "97\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "out2, hx2, padded_x, padded_rnn_hxs, output, output_hx = gru2(obs, rnn_hxs, dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0bcfe1be-7c6f-4870-bbe5-4ffa89ffc32a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.4506e-09,  2.7940e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -7.4506e-09,  0.0000e+00,  0.0000e+00,  3.7253e-09,\n",
       "          0.0000e+00,  0.0000e+00, -7.4506e-09,  7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4901e-08,\n",
       "          0.0000e+00, -1.4901e-08, -3.7253e-09,  1.4901e-08,  0.0000e+00,\n",
       "         -7.4506e-09,  0.0000e+00, -9.3132e-10,  0.0000e+00,  0.0000e+00,\n",
       "          1.4901e-08,  0.0000e+00,  0.0000e+00,  1.8626e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4901e-08,  7.4506e-09,\n",
       "          3.7253e-09,  7.4506e-09,  0.0000e+00,  0.0000e+00],\n",
       "        [-1.4901e-08,  1.8626e-09,  3.7253e-09, -1.8626e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.4901e-08, -7.4506e-09, -7.4506e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4901e-08,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "         -1.8626e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.4901e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4901e-08,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7253e-09,\n",
       "          1.4901e-08,  1.4901e-08,  0.0000e+00,  7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4901e-08,  0.0000e+00,\n",
       "          5.5879e-09,  0.0000e+00,  0.0000e+00,  3.7253e-09],\n",
       "        [-1.4901e-08, -7.4506e-09,  0.0000e+00, -1.8626e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.4901e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.4901e-08, -7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.8626e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  7.4506e-09, -7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  3.7253e-09,  7.4506e-09, -1.4901e-08,  1.4901e-08,\n",
       "          0.0000e+00,  0.0000e+00,  7.4506e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  5.5879e-09,  0.0000e+00, -3.7253e-09,\n",
       "          1.4901e-08,  1.4901e-08, -1.8626e-09,  0.0000e+00, -7.4506e-09,\n",
       "          0.0000e+00,  7.4506e-09,  0.0000e+00,  1.4901e-08, -7.4506e-09,\n",
       "          1.1176e-08, -7.4506e-09, -7.4506e-09,  7.4506e-09],\n",
       "        [-1.4901e-08, -7.4506e-09,  0.0000e+00,  3.7253e-09,  0.0000e+00,\n",
       "         -1.4901e-08,  1.4901e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.4901e-08,  0.0000e+00,  7.4506e-09,  1.4901e-08,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.4901e-08,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -3.7253e-09,  0.0000e+00,  1.4901e-08,\n",
       "          0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00, -1.8626e-09,\n",
       "          1.8626e-09,  7.4506e-09, -7.4506e-09,  0.0000e+00,  0.0000e+00,\n",
       "         -7.4506e-09, -3.7253e-09,  1.4901e-08,  0.0000e+00,  0.0000e+00,\n",
       "          1.4901e-08,  1.4901e-08,  7.4506e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.7253e-09, -7.4506e-09, -7.4506e-09,\n",
       "          0.0000e+00,  0.0000e+00, -2.7940e-09,  0.0000e+00, -7.4506e-09,\n",
       "          0.0000e+00,  7.4506e-09,  0.0000e+00,  1.4901e-08, -7.4506e-09,\n",
       "          9.3132e-09, -7.4506e-09,  0.0000e+00,  1.1176e-08],\n",
       "        [-1.4901e-08, -3.7253e-09,  0.0000e+00,  1.8626e-09,  0.0000e+00,\n",
       "          0.0000e+00,  2.9802e-08, -1.4901e-08,  0.0000e+00,  0.0000e+00,\n",
       "         -1.4901e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -7.4506e-09,  1.8626e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.8626e-09,  7.4506e-09, -3.7253e-09,\n",
       "          2.7940e-09,  0.0000e+00, -7.4506e-09,  3.7253e-09,  0.0000e+00,\n",
       "          0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  7.4506e-09,  0.0000e+00, -1.4901e-08,\n",
       "          0.0000e+00, -1.4901e-08, -5.5879e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4506e-09,\n",
       "          3.7253e-09, -3.7253e-09, -1.4901e-08,  1.4901e-08],\n",
       "        [ 0.0000e+00,  3.7253e-09, -7.4506e-09,  2.7940e-09,  0.0000e+00,\n",
       "          0.0000e+00,  1.4901e-08,  0.0000e+00, -7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00,\n",
       "         -7.4506e-09,  0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  9.3132e-10,  3.7253e-09, -1.8626e-09,\n",
       "          1.8626e-09, -3.7253e-09, -3.7253e-09,  1.8626e-09, -7.4506e-09,\n",
       "          0.0000e+00, -3.7253e-09,  0.0000e+00,  0.0000e+00, -1.4901e-08,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00, -7.4506e-09,\n",
       "         -7.4506e-09,  0.0000e+00, -3.2596e-09, -7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -1.8626e-09, -3.7253e-09, -1.4901e-08,  1.4901e-08],\n",
       "        [ 0.0000e+00,  3.7253e-09, -7.4506e-09,  1.8626e-09,  7.4506e-09,\n",
       "          0.0000e+00,  1.4901e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4506e-09,  1.4901e-08,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7253e-09,  0.0000e+00,\n",
       "         -7.4506e-09,  7.4506e-09,  3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.2596e-09,  3.7253e-09,  1.8626e-09,\n",
       "          1.8626e-09, -7.4506e-09, -1.8626e-09,  1.8626e-09,  0.0000e+00,\n",
       "          0.0000e+00,  3.7253e-09,  0.0000e+00,  0.0000e+00, -1.4901e-08,\n",
       "          0.0000e+00,  0.0000e+00, -3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  7.4506e-09, -3.7253e-09,  0.0000e+00, -7.4506e-09,\n",
       "          0.0000e+00,  0.0000e+00, -1.8626e-09, -7.4506e-09,  0.0000e+00,\n",
       "          0.0000e+00,  5.5879e-09,  0.0000e+00,  3.7253e-09,  7.4506e-09,\n",
       "          3.7253e-09, -3.7253e-09,  0.0000e+00,  1.4901e-08],\n",
       "        [-2.4345e-02, -2.4244e-02, -7.9860e-02, -2.7669e-02,  6.6794e-03,\n",
       "         -6.2410e-02, -4.2982e-03, -2.1879e-03,  1.6339e-03,  7.1289e-02,\n",
       "          7.0352e-02,  1.2625e-02,  4.9170e-02, -3.0548e-02, -3.9058e-02,\n",
       "         -8.3944e-02, -5.6804e-02, -2.2943e-02,  2.5739e-02, -2.4876e-02,\n",
       "          5.5424e-02,  4.6656e-02, -2.5954e-02, -5.0452e-02, -3.5546e-02,\n",
       "          9.6303e-02,  1.9292e-02,  3.7238e-03,  2.4467e-02,  1.3823e-02,\n",
       "         -2.8631e-03, -4.7348e-02,  6.3779e-03,  4.3876e-02,  2.0559e-02,\n",
       "         -3.1111e-02,  1.4958e-02, -8.3494e-02,  3.0275e-02,  1.3221e-02,\n",
       "          5.2305e-03, -2.0127e-02, -4.8921e-03,  4.3257e-02,  3.6838e-02,\n",
       "         -5.1316e-03,  2.9789e-02,  4.3816e-02, -1.1608e-01, -3.9882e-02,\n",
       "          1.8343e-02,  5.4955e-02, -3.7797e-02,  3.6602e-02, -4.3625e-02,\n",
       "         -4.5199e-02,  6.1206e-02, -2.3029e-02,  1.6334e-02, -1.3294e-02,\n",
       "          3.5891e-02, -2.9721e-02,  5.4780e-02,  5.9623e-02],\n",
       "        [-1.4877e-02, -2.5007e-02, -5.1007e-02, -1.8055e-02, -2.1114e-03,\n",
       "         -3.3816e-02, -1.2289e-02,  7.1521e-03,  1.5347e-03,  3.6079e-02,\n",
       "          4.3014e-02,  1.5436e-03,  3.2712e-02, -1.7223e-02, -1.5033e-02,\n",
       "         -4.7101e-02, -2.9369e-02, -1.9662e-02,  1.2135e-02, -7.0527e-03,\n",
       "          4.0261e-02,  2.5503e-02, -1.4092e-02, -2.3720e-02, -2.0875e-02,\n",
       "          5.8865e-02,  8.6041e-03,  2.6778e-03,  2.0436e-02,  3.4428e-03,\n",
       "         -1.1375e-02, -3.1916e-02,  4.8333e-03,  1.9170e-02,  1.4240e-02,\n",
       "         -1.1644e-02,  6.1298e-03, -4.5677e-02,  6.9333e-03,  1.8238e-03,\n",
       "          2.5270e-03, -9.9807e-03, -4.7128e-03,  2.3904e-02,  2.1425e-02,\n",
       "         -7.0508e-03,  1.3368e-02,  1.9773e-02, -6.8777e-02, -2.2686e-02,\n",
       "          4.3695e-03,  3.5223e-02, -1.3203e-02,  2.1972e-02, -2.4902e-02,\n",
       "         -2.3117e-02,  3.7848e-02, -1.0434e-02,  1.4368e-04, -1.6491e-03,\n",
       "          2.1593e-02, -1.3070e-02,  3.7775e-02,  2.4365e-02],\n",
       "        [-7.8380e-03, -1.9839e-02, -3.0780e-02, -1.1677e-02, -3.4598e-03,\n",
       "         -1.8728e-02, -1.2236e-02,  7.9842e-03,  2.3418e-03,  1.8643e-02,\n",
       "          2.5609e-02, -1.7684e-03,  2.0972e-02, -1.0075e-02, -5.3096e-03,\n",
       "         -2.7253e-02, -1.4553e-02, -1.5262e-02,  5.6046e-03, -2.0604e-04,\n",
       "          2.8353e-02,  1.2639e-02, -6.9800e-03, -9.2144e-03, -1.1627e-02,\n",
       "          3.5821e-02,  3.8233e-03,  1.2849e-03,  1.4158e-02, -6.0585e-04,\n",
       "         -1.2013e-02, -2.0469e-02,  3.3075e-03,  7.4735e-03,  8.5465e-03,\n",
       "         -3.4187e-03,  1.6289e-03, -2.3213e-02, -8.7865e-05, -1.7768e-03,\n",
       "          1.8836e-03, -4.6658e-03, -3.2961e-03,  1.2913e-02,  1.1891e-02,\n",
       "         -6.2637e-03,  7.4677e-03,  1.0212e-02, -3.9914e-02, -1.2341e-02,\n",
       "          8.2060e-04,  2.1665e-02, -2.4029e-03,  1.2104e-02, -1.4373e-02,\n",
       "         -1.2321e-02,  2.2519e-02, -3.2715e-03, -3.7846e-03,  1.6461e-03,\n",
       "          1.2510e-02, -5.4469e-03,  2.5265e-02,  8.2664e-03],\n",
       "        [-3.4701e-03, -1.3843e-02, -1.8230e-02, -7.1125e-03, -2.7918e-03,\n",
       "         -1.0429e-02, -9.4427e-03,  6.0647e-03,  2.8341e-03,  9.9618e-03,\n",
       "          1.5083e-02, -2.3369e-03,  1.2598e-02, -5.9875e-03, -1.8374e-03,\n",
       "         -1.5939e-02, -7.3747e-03, -1.0701e-02,  2.4184e-03,  2.1152e-03,\n",
       "          1.9363e-02,  5.8878e-03, -3.1291e-03, -1.9051e-03, -6.7215e-03,\n",
       "          2.1990e-02,  1.8956e-03,  3.8703e-04,  8.8571e-03, -1.7714e-03,\n",
       "         -1.0255e-02, -1.2295e-02,  2.0909e-03,  2.4929e-03,  4.6615e-03,\n",
       "         -7.2949e-05, -2.8788e-04, -1.1100e-02, -1.8934e-03, -2.0711e-03,\n",
       "          1.5584e-03, -1.9597e-03, -1.9635e-03,  6.6482e-03,  5.9986e-03,\n",
       "         -4.7594e-03,  5.2310e-03,  6.3307e-03, -2.3019e-02, -6.7511e-03,\n",
       "          2.1707e-04,  1.3201e-02,  1.6148e-03,  5.8780e-03, -8.4206e-03,\n",
       "         -6.9588e-03,  1.3147e-02, -1.1447e-04, -3.8290e-03,  2.0249e-03,\n",
       "          7.1681e-03, -2.0241e-03,  1.6038e-02,  1.6143e-03],\n",
       "        [-1.1487e-03, -8.9281e-03, -1.0827e-02, -4.0306e-03, -1.8363e-03,\n",
       "         -6.0115e-03, -6.6463e-03,  4.1495e-03,  2.7045e-03,  5.5980e-03,\n",
       "          8.8165e-03, -2.0322e-03,  7.1204e-03, -3.5687e-03, -7.3428e-04,\n",
       "         -9.4430e-03, -3.8097e-03, -7.0537e-03,  9.0341e-04,  2.5156e-03,\n",
       "          1.2948e-02,  2.5474e-03, -1.2494e-03,  1.1440e-03, -4.0115e-03,\n",
       "          1.3474e-02,  1.0228e-03, -5.0638e-05,  5.2443e-03, -1.8291e-03,\n",
       "         -7.9490e-03, -6.9729e-03,  1.2189e-03,  4.9464e-04,  2.4675e-03,\n",
       "          1.1344e-03, -8.5776e-04, -5.0009e-03, -1.8986e-03, -1.4186e-03,\n",
       "          1.1527e-03, -7.9552e-04, -9.9444e-04,  3.1642e-03,  2.6426e-03,\n",
       "         -3.3843e-03,  4.0083e-03,  4.3591e-03, -1.3146e-02, -3.6937e-03,\n",
       "          2.1306e-04,  8.0265e-03,  2.6468e-03,  2.2916e-03, -5.0005e-03,\n",
       "         -3.9651e-03,  7.5071e-03,  1.0035e-03, -2.9720e-03,  1.5359e-03,\n",
       "          4.0656e-03, -5.8796e-04,  9.7573e-03, -7.3979e-04]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we get same result for output after rebatching\n",
    "\n",
    "(out1 - out2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df76fa5-8430-4f6f-926d-c0f22c6bad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we do NOT get the same result for the hidden state output since padding adds\n",
    "#  steps of zeros which cause more evolution in rnn_hxs output\n",
    "(hx1 - hx2)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0b482-6722-4bde-be3d-0f7da59e2602",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing policy\n",
    "\n",
    "Actually this Q learning agent seems to learn much better direct navigation rather than the corner testing of previous agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62502322-10cc-474e-b3d5-5f2cd70d16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume recurrent policy\n",
    "\n",
    "env_kwargs = {\n",
    "    'num_objects': 0, 'rew_structure': 'goal',\n",
    "    'task_structure': 2, 'wall_colors': 4,\n",
    "    'num_rays': 12, 'fov': 1\n",
    "}\n",
    "env = gym.make('NavEnv-v0', **env_kwargs)\n",
    "qnet = torch.load('../saved_models/mwm_base1_t0.pt')\n",
    "agent = R2D2Agent(q_network=qnet, deterministic=False, env=env,\n",
    "                 start_e=0.05, end_e=0.05)\n",
    "\n",
    "def evaluate_policy(agent, num_episodes=10):\n",
    "    \n",
    "    ep_lengths = []\n",
    "    ep_returns = []\n",
    "    \n",
    "    ep_l = 0\n",
    "    ep_r = 0\n",
    "    for t in range(num_episodes):\n",
    "        obs = agent.env.reset()\n",
    "        rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "        while True:\n",
    "            action, q_values, next_rnn_hxs = agent.act(obs, rnn_hxs)\n",
    "            next_obs, reward, done, info = agent.env.step(action.item())\n",
    "            \n",
    "            ep_l += 1\n",
    "            ep_r += reward\n",
    "            if done:\n",
    "                next_obs = agent.env.reset()\n",
    "                next_rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "                \n",
    "                ep_lengths.append(ep_l)\n",
    "                ep_returns.append(ep_r)\n",
    "                ep_l = 0\n",
    "                ep_r = 0\n",
    "                break\n",
    "                \n",
    "            obs = next_obs\n",
    "            rnn_hxs = next_rnn_hxs\n",
    "    return ep_lengths, ep_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6dbca203-100e-4233-8c00-74cd7956077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(agent, data_callback=None,\n",
    "             num_episodes=10, verbose=0, with_activations=False):\n",
    "    '''\n",
    "    data_callback: a function that should be called at each step to pull information\n",
    "        from the environment if needed. The function will take arguments\n",
    "            def callback(actor_critic, vec_envs, recurrent_hidden_states, data):\n",
    "        actor_critic: the actor_critic network\n",
    "        vec_envs: the vec envs (can call for example vec_envs.get_attr('objects') to pull data)\n",
    "        recurrent_hidden_states: these are given in all data, but may want to use in computation\n",
    "        obs: observation this step (after taking action) - \n",
    "            note that initial observation is never seen by data_callback\n",
    "            also note that this observation will have the mean normalized\n",
    "            so may instead want to call vec_envs.get_method('get_observation')\n",
    "        action: actions this step\n",
    "        reward: reward this step\n",
    "        data: a data dictionary that will continuously be passed to be updated each step\n",
    "            it will start as an empty dicionary, so keys must be initialized\n",
    "        see below at example_data_callback in this file for an example\n",
    "    '''\n",
    "    ep_rewards = []\n",
    "    \n",
    "    ep_r = 0\n",
    "\n",
    "    all_obs = []\n",
    "    all_actions = []\n",
    "    all_rewards = []\n",
    "    all_hidden_states = []\n",
    "    all_dones = []\n",
    "    all_activations = []\n",
    "    data = {}\n",
    "\n",
    "    obs = agent.env.reset()\n",
    "    rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "\n",
    "    step = 0\n",
    "    for i in range(num_episodes):\n",
    "        while True:\n",
    "            all_hidden_states.append(rnn_hxs)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                action, q_values, rnn_hxs = agent.act(obs, rnn_hxs)\n",
    "\n",
    "            obs, reward, done, infos = agent.env.step(action)\n",
    "\n",
    "            all_obs.append(obs)\n",
    "            all_actions.append(action)\n",
    "            all_rewards.append(reward)\n",
    "            all_dones.append(done)\n",
    "\n",
    "            if with_activations:\n",
    "                all_activations.append(outputs['activations'])\n",
    "\n",
    "            if data_callback is not None:\n",
    "                data = data_callback(agent, env, rnn_hxs,\n",
    "                    obs, action, reward, done, data)\n",
    "            else:\n",
    "                data = {}\n",
    "                \n",
    "            if done:\n",
    "                obs = agent.env.reset()\n",
    "                rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "                ep_rewards.append(ep_r)\n",
    "                ep_r = 0\n",
    "                break\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print(\" Evaluation using {} episodes: mean reward {:.5f}\\n\".format(\n",
    "            len(ep_rewards), np.mean(ep_rewards)))\n",
    "\n",
    "    return {\n",
    "        'obs': all_obs,\n",
    "        'actions': all_actions,\n",
    "        'rewards': all_rewards,\n",
    "        'hidden_states': all_hidden_states,\n",
    "        'dones': all_dones,\n",
    "        'data': data,\n",
    "        'activations': all_activations,\n",
    "    }\n",
    "\n",
    "\n",
    "def nav_data_callback(actor_critic, vec_envs, recurrent_hidden_states,\n",
    "                                  obs, action, reward, done, data):\n",
    "    if data == {}:\n",
    "        data['pos'] = []\n",
    "        data['angle'] = []\n",
    "    \n",
    "    # pos = [c.pos.copy() for c in vec_envs.get_attr('character')]\n",
    "    # angle = [c.angle for c in vec_envs.get_attr('character')]\n",
    "    pos = env.character.pos.copy()\n",
    "    angle = env.character.angle\n",
    "    data['pos'].append(pos)\n",
    "    data['angle'].append(angle)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ea2196c-71ee-42f0-9375-7ea08d2a39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_agent(agent, nav_data_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e422f5d-51f6-4130-a140-4887d0af5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_ep(targets, dones):\n",
    "    '''\n",
    "    Given a collection of res data from an evalu() call, split up\n",
    "    the data by episodes using res['dones']. Uses the True values from\n",
    "    dones list to tell when a \n",
    "    \n",
    "    For example, \n",
    "    res = evalu(...)\n",
    "    ep_pos = split_by_ep(res['data']['pos'], res['dones'])\n",
    "    '''\n",
    "    done_idxs = np.where(np.vstack(dones))[0]\n",
    "    split_targets = []\n",
    "    for i in range(len(done_idxs)):\n",
    "        if i == 0:\n",
    "            done_targets = targets[:done_idxs[i]]\n",
    "        else:\n",
    "            done_targets = targets[done_idxs[i-1]:done_idxs[i]]\n",
    "\n",
    "        split_targets.append(done_targets)\n",
    "    return split_targets\n",
    "\n",
    "def draw_trajectory(pos=None, angle=None, fig=None, ax=None):\n",
    "    '''Convert positions and angles into an image trajectory\n",
    "    Adds a few extra details like where the start and goal reached locations are\n",
    "    as well as adding increasing redness as the agent spends time in one spot rotating\n",
    "    without forward movement'''\n",
    "    if fig == None and ax == None:\n",
    "        fig, ax = pplt.subplots()\n",
    "    stopped = 0\n",
    "    last_p = np.zeros(2)\n",
    "    for i, (p, a) in enumerate(zip(pos, angle)):\n",
    "        redness = max(0, 1-stopped*0.1)\n",
    "        color = [1, redness, redness, 1]\n",
    "        draw_character(p, a, ax=ax, color=color)\n",
    "\n",
    "        if (p == last_p).all():\n",
    "            stopped += 1\n",
    "        else:\n",
    "            stopped = 0\n",
    "        last_p = p\n",
    "\n",
    "    #redraw first and last steps\n",
    "    draw_character(pos[0], angle[0], color=[0, 1, 0, 1], size=18, ax=ax)\n",
    "    if len(pos) < 202:\n",
    "        draw_character(pos[-1], angle[-1], color=[0, 1, 1, 1], size=18, ax=ax)\n",
    "    ax.format(xlim=[0, 300], ylim=[0, 300])\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def draw_character(pos, angle, size=10, ax=None, color=None):\n",
    "    '''\n",
    "    Given a position and angle, draw character to the given axis\n",
    "    '''\n",
    "    angle1 = angle - 0.3\n",
    "    angle2 = angle + 0.3\n",
    "    point1 = [pos[0], pos[1]]\n",
    "    point2 = [pos[0] - np.cos(angle1)*size, pos[1] - np.sin(angle1)*size]\n",
    "    point3 = [pos[0] - np.cos(angle2)*size, pos[1] - np.sin(angle2)*size]\n",
    "\n",
    "    if color is None:\n",
    "        color = np.array([0.9, 0.9, 0])\n",
    "\n",
    "    poly = plt.Polygon([point1, point2, point3], fc=color)\n",
    "    if ax is None:\n",
    "        plt.gca().add_patch(poly)\n",
    "    else:\n",
    "        ax.add_patch(poly)\n",
    "        \n",
    "        \n",
    "def set_trajectory_plot_style(reset=False):\n",
    "    '''Set up rc params for proplot so that we get nice images to feed into\n",
    "    the visual system for ananlysis\n",
    "    \n",
    "    If reset == True, revert to default rcprams for normal plotting'''\n",
    "    if reset:\n",
    "        pplt.rc.reset()\n",
    "    else:\n",
    "        pplt.rc.update({\n",
    "            'axes.spines.bottom': False,\n",
    "            'axes.spines.top': False,\n",
    "            'axes.spines.left': False,\n",
    "            'axes.spines.right': False,\n",
    "            'axes.facecolor': 'black',\n",
    "            'axes.grid': False\n",
    "        })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "660824bb-9e33-4f13-ab58-e11c33554bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trajectory_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80307784-2b09-4ad0-bdb3-22d15fc869d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_dones = split_by_ep(res['dones'], res['dones'])\n",
    "ep_pos = split_by_ep(res['data']['pos'], res['dones'])\n",
    "ep_angle = split_by_ep(res['data']['angle'], res['dones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f1934e6-024c-4e58-aa9e-42b7b9068b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 9, 49, 202, 74, 187, 115, 34, 202, 94]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(d) for d in ep_dones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19e2a01c-247b-4ae5-962c-718295f86d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import proplot as pplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4be85b1-e3b7-4b6c-9331-aaea7cccdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99fccdba-8a31-4ba1-a5be-74b415eb68c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Figure(nrows=1, ncols=1, refwidth=2.5),\n",
       " SubplotGrid(nrows=1, ncols=1, length=1))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "Figure(nrows=1, ncols=1, refwidth=2.5)"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 262,
       "width": 262
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "i += 1\n",
    "draw_trajectory(ep_pos[i], ep_angle[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d096de3-e8e7-4fbd-8d63-5326a5e5060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.vstack(res['data']['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "df77f9b4-a3bd-42b1-a795-a6e22bef0159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x28e4ac1e640>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 400,
       "width": 400
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pos.T[0], pos.T[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3485b3-7c25-453b-a3ee-39012ade010e",
   "metadata": {},
   "source": [
    "# Testing speed bottlenecks\n",
    "\n",
    "Since we know that previous PPO could hit ~2000-3000SPS, but now we get closer to 300-600, let's double check to see where the implementation is bottlenecked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8606ebdf-4982-4f8e-b745-c40a75139ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=0, start_e=0, buffer_size=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73cd28c9-0c8f-488c-964f-a3c5a1251907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 ms ± 14.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "\n",
    "'''Collection: with epsilon=0, 500 steps of collection \n",
    "already takes about 500ms, taking about 50% of our SPS budget. \n",
    "Might need to be vectorizing/parallelizing'''\n",
    "\n",
    "agent.collect(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "760fe10d-b484-45e1-b6f9-b00f2ead32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 ms ± 14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "'''Simulation: takes about 20% of the acting time'''\n",
    "\n",
    "env = agent.env\n",
    "\n",
    "env.reset()\n",
    "for i in range(640):\n",
    "    obs, r, done, info = env.step(env.action_space.sample())\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9a781fa-fa88-434d-b0d5-daf5840fba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.collect(80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf2634cd-f799-4568-b041-2205a8161729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582 µs ± 46.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sample = agent.rb.sample(64//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3b04f8d2-1b16-4d42-a2e0-9abbb4869b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620 µs ± 36.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sample = agent.rb.sample(256//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3c6b23dc-f622-47b8-8b0d-60a81f63770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32 ms ± 124 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sample = agent.rb.sample(64//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac427dfc-ca46-4ddd-93f8-a237a325560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32 ms ± 178 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sample = agent.rb.sample(256//4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd4f43-8fab-4bf5-bc85-4e9a8c25a26d",
   "metadata": {},
   "source": [
    "# Batched and vectorized envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9c4ece2-271a-47e7-8603-e3b2014dead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=0, start_e=0.5, buffer_size=80000, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9454bb2-8398-461e-acaa-071836454c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hxs = agent.get_rnn_hxs()\n",
    "obs = agent.env.reset()\n",
    "obs = torch.tensor(obs).unsqueeze(1)\n",
    "\n",
    "action, q, next_rnn_hxs = agent.act(obs, rnn_hxs)\n",
    "next_obs, rew, done, info = agent.env.step(action)\n",
    "masks = torch.FloatTensor(\n",
    "    [[0.0] if done_ else [1.0] for done_ in done])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6814f24-0b05-4aa0-aee3-64de7292d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.collect(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aceee2ad-3d09-4b81-a3c7-83aa1df370d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5564d352-5e40-4949-bd1c-1acef29db1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 ms ± 218 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fc2fdb22-f3fb-4e1d-8918-6f417592ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=0, start_e=0.5, buffer_size=80000, n_envs=1)\n",
    "\n",
    "action, q, next_rnn_hxs = agent.act(agent.obs, agent.rnn_hxs, masks=agent.masks)\n",
    "next_obs, rew, done, info = agent.env.step(action)\n",
    "agent.masks = torch.FloatTensor(\n",
    "    [[0.0] if done_ else [1.0] for done_ in done])\n",
    "\n",
    "agent.obs = next_obs\n",
    "agent.rnn_hxs = next_rnn_hxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d3e8a95-77cf-407d-b984-4c9b8bfceddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = agent.rb.sample(agent.batch_size//agent.sequence_length)\n",
    "states = sample['observations']\n",
    "next_states = sample['next_observations']\n",
    "hidden_states = sample['hidden_states']\n",
    "next_hidden_states = sample['next_hidden_states']\n",
    "actions = sample['actions']\n",
    "rewards = sample['rewards']\n",
    "dones = sample['dones']\n",
    "next_dones = sample['next_dones']\n",
    "\n",
    "with torch.no_grad():\n",
    "    target_q, _, _ = agent.target_network(next_states, next_hidden_states, next_dones)\n",
    "    target_max, _ = target_q.max(dim=2)\n",
    "    td_target = rewards + agent.gamma * target_max * (1 - dones)\n",
    "old_q, _, _ = agent.q_network(states, hidden_states, dones)\n",
    "old_val = old_q.gather(2, actions.long()).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df0b8d6-b53b-4b3b-98cc-e33f2bab4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = make_vec_envs('NavEnv-v0',  2, env_kwargs=env_kwargs)\n",
    "rb = SequenceReplayBuffer(10000, envs.observation_space, envs.action_space,\n",
    "                     64, 4, 2, 2)\n",
    "rnn_hxs2 = agent.q_network.get_rnn_hxs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43addd8-7596-45d3-9348-09df9ba84b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2D2Agent(\n",
       "  (q_network): RNNQNetwork(\n",
       "    (relu): ReLU()\n",
       "    (gru): ResettingGRUBatched(\n",
       "      (gru): GRU(24, 64, batch_first=True)\n",
       "    )\n",
       "    (fc0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       "  (target_network): RNNQNetwork(\n",
       "    (relu): ReLU()\n",
       "    (gru): ResettingGRUBatched(\n",
       "      (gru): GRU(24, 64, batch_first=True)\n",
       "    )\n",
       "    (fc0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Run steps manually'''\n",
    "\n",
    "obs = agent.env.reset()\n",
    "rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "for i in range(500):\n",
    "    action, q_values, next_rnn_hxs = agent.act(obs, rnn_hxs)\n",
    "    next_obs, reward, done, info = agent.env.step(action.item())\n",
    "    \n",
    "    if reward == 1:\n",
    "        break\n",
    "        \n",
    "    if done:\n",
    "        next_obs = agent.env.reset()\n",
    "        next_rnn_hxs = agent.q_network.get_rnn_hxs()\n",
    "    \n",
    "    obs = next_obs\n",
    "    rnn_hxs = next_rnn_hxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89704bd3-d795-454f-8f9c-dd69a812b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=0, start_e=0.5, buffer_size=80000, n_envs=1)\n",
    "\n",
    "agent.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88c89e-e616-4dd7-8612-ea9e4ec1dd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "550443b4-589c-49d9-8438-9ab3aec9516c",
   "metadata": {},
   "source": [
    "# Testing ResettingGRUBatched\n",
    "\n",
    "Manual lines for debugging the forward call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "873ca769-9425-48f6-baf8-802d5aa58bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=0, start_e=0.5, buffer_size=80000, n_envs=16)\n",
    "agent.collect(500)\n",
    "sample = agent.rb.sample(agent.batch_size//agent.sequence_length)\n",
    "states = sample['observations']\n",
    "next_states = sample['next_observations']\n",
    "hidden_states = sample['hidden_states']\n",
    "\n",
    "gru = agent.q_network.gru.gru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fd6aa20-f0c6-4fe3-a118-8b8c3f07d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e667866-70b3-44dd-b3e5-26c18e3a76f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19e0470c-23a9-4d6a-b3ea-165e657efc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For batched forward pass\n",
    "    x: (N, L, H_in)\n",
    "    hidden_state: (1, L, hidden_size)\n",
    "    dones: (N, L)\n",
    "\n",
    "For unbatched\n",
    "    x: (L, H_in)\n",
    "    hidden_state: (L, hidden_size)\n",
    "    dones: (L,)\n",
    "\n",
    "Note that in unbatched, we will actually turn it into a batch\n",
    "    hence we have a line of unsqueezes\n",
    "hidden_state has first dimension of 1 indicating 1 layer and not bi-directional\n",
    "\n",
    "Output: full_out (N, L, hidden_size), full_hx_out (1, N, hidden_size)\n",
    "    Note that full_hx_out is NOT GENERALLY the same as the rnn_hidden_state\n",
    "    you would expect from standard gru unit, since we sometimes pad the ending\n",
    "    More correct to generally just take the last step of full_out\n",
    "'''\n",
    "x = next_states\n",
    "hidden_state = next_hidden_states\n",
    "dones = next_dones\n",
    "masks = None\n",
    "\n",
    "\n",
    "if hidden_state.dim() == 2:\n",
    "    hidden_state = hidden_state.unsqueeze(0)\n",
    "    x = x.unsqueeze(0)\n",
    "    dones = dones.unsqueeze(0)\n",
    "\n",
    "num_batches = x.shape[0]\n",
    "\n",
    "extra_rows = int(dones.sum().item())\n",
    "\n",
    "#Generate a new padded x and rnn_hxs vector to batch forward pass\n",
    "padded_x = torch.zeros((num_batches + extra_rows, x.shape[1], x.shape[2]))\n",
    "padded_rnn_hxs = torch.zeros((hidden_state.shape[0], num_batches + extra_rows, hidden_state.shape[2]))\n",
    "\n",
    "batchable_rows = (dones == 0).all(dim=1)\n",
    "num_batchable_rows = batchable_rows.sum().item()\n",
    "individual_rows = (~batchable_rows).argwhere().reshape(-1)\n",
    "\n",
    "#First N rows will be taken from rows with no dones\n",
    "padded_x[:num_batchable_rows] = x[batchable_rows]\n",
    "padded_rnn_hxs[:, :num_batchable_rows, :] = hidden_state[:, batchable_rows, :]\n",
    "# padded_rnn_hxs[:num_batchable_rows] = hidden_state[batchable_rows]\n",
    "\n",
    "#Remaining rows will be filled out in order of rows with dones\n",
    "cur_row_idx = num_batchable_rows\n",
    "for i in individual_rows:\n",
    "    breakpoints = (dones[i] == 1).argwhere()\n",
    "    cur_idx = 0\n",
    "    rnn_hx = hidden_state[:, i, :]\n",
    "\n",
    "    for breakpoint in breakpoints:\n",
    "        if breakpoint == 0:\n",
    "            rnn_hx = agent.get_rnn_hxs()\n",
    "            continue\n",
    "        padded_x[cur_row_idx, :breakpoint-cur_idx, :] = x[i, cur_idx:breakpoint, :]\n",
    "        padded_rnn_hxs[:, cur_row_idx, :] = rnn_hx\n",
    "        # padded_rnn_hxs[cur_row_idx] = rnn_hx\n",
    "\n",
    "        rnn_hx = agent.get_rnn_hxs()\n",
    "        cur_idx = breakpoint\n",
    "        cur_row_idx += 1\n",
    "\n",
    "    if cur_idx < len(dones[i]):\n",
    "        padded_x[cur_row_idx, :len(dones[i])-cur_idx, :] = x[i, cur_idx:, :]\n",
    "        padded_rnn_hxs[:, cur_row_idx, :] = rnn_hx\n",
    "        # padded_rnn_hxs[cur_row_idx] = rnn_hx\n",
    "        cur_row_idx += 1\n",
    "\n",
    "#Perform forward pass on new batched\n",
    "output, output_hx = gru(padded_x, padded_rnn_hxs)\n",
    "\n",
    "#Fill out the expected output by reversing the whole process\n",
    "full_out = torch.zeros((x.shape[0], x.shape[1], agent.hidden_size))\n",
    "full_hx_out = torch.zeros((1, x.shape[0], agent.hidden_size))\n",
    "\n",
    "full_out[batchable_rows] = output[:num_batchable_rows]\n",
    "full_hx_out[:, batchable_rows, :] = output_hx[:, :num_batchable_rows, :]\n",
    "# full_hx_out[batchable_rows] = output_hx[:num_batchable_rows]\n",
    "\n",
    "cur_row_idx = num_batchable_rows\n",
    "for i in individual_rows:\n",
    "    breakpoints = (dones[i] == 1).argwhere()\n",
    "    cur_idx = 0\n",
    "\n",
    "    for breakpoint in breakpoints:\n",
    "        if breakpoint == 0:\n",
    "            continue\n",
    "        full_out[i, cur_idx:breakpoint, :] = output[cur_row_idx, :breakpoint-cur_idx, :]\n",
    "\n",
    "        cur_idx = breakpoint\n",
    "        cur_row_idx += 1\n",
    "\n",
    "    if cur_idx < len(dones[i]):\n",
    "        full_out[i, cur_idx:, :] = output[cur_row_idx, :len(dones[i])-cur_idx, :]\n",
    "\n",
    "        #Remember only the last rnn hidden state gets returned\n",
    "        full_hx_out[:, i, :] = output_hx[:, cur_row_idx, :]\n",
    "        # full_hx_out[i] = output_hx[cur_row_idx]\n",
    "        cur_row_idx += 1\n",
    "    else:\n",
    "        #If we did not have remaining steps to fill, then we must have had a done\n",
    "        # on the last step, so the final rnn_hx should be zeros to return\n",
    "        full_hx_out[:, i, :] = agent.get_rnn_hxs()\n",
    "        # full_hx_out[i] = self.get_rnn_hxs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198bf89-e6b9-4afd-a7c1-ef9a18ba7a2c",
   "metadata": {},
   "source": [
    "# Test loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47291a3c-7107-4f3d-9fe9-2a04de22888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network = torch.load('../saved_models/mwm_batch1024_t0.pt')\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs, q_network=q_network,\n",
    "                 verbose=2, start_e=0.05, n_envs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8103960-ac6a-4917-adad-45b7e069072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode R: 1.0, L: 23.0\n",
      "Episode R: 1.0, L: 27.0\n",
      "Episode R: 1.0, L: 23.0\n",
      "Episode R: 1.0, L: 9.0\n",
      "Episode R: 1.0, L: 84.0\n",
      "Episode R: 1.0, L: 77.0\n",
      "Episode R: 1.0, L: 11.0\n",
      "Episode R: 1.0, L: 38.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 157.0\n",
      "Episode R: 1.0, L: 70.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 18.0\n",
      "Episode R: 1.0, L: 14.0\n",
      "Episode R: 1.0, L: 49.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 35.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 24.0\n",
      "Episode R: 1.0, L: 39.0\n",
      "Episode R: 1.0, L: 9.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 41.0\n",
      "Episode R: 1.0, L: 29.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 41.0\n",
      "Episode R: 1.0, L: 10.0\n",
      "Episode R: 1.0, L: 36.0\n",
      "Episode R: 1.0, L: 16.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 28.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 63.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 9.0\n",
      "Episode R: 1.0, L: 15.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 11.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 99.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 23.0\n",
      "Episode R: 1.0, L: 23.0\n",
      "Episode R: 1.0, L: 26.0\n",
      "Episode R: 1.0, L: 29.0\n",
      "Episode R: 1.0, L: 32.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 21.0\n",
      "Episode R: 1.0, L: 158.0\n",
      "Episode R: 1.0, L: 37.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 68.0\n",
      "Episode R: 1.0, L: 33.0\n",
      "Episode R: 1.0, L: 25.0\n",
      "Episode R: 1.0, L: 120.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 27.0\n",
      "Episode R: 1.0, L: 24.0\n",
      "Episode R: 1.0, L: 63.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 157.0\n",
      "Episode R: 1.0, L: 28.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 189.0\n",
      "Episode R: 1.0, L: 152.0\n",
      "Episode R: 1.0, L: 20.0\n",
      "Episode R: 1.0, L: 30.0\n",
      "Episode R: 0.0, L: 202.0\n",
      "Episode R: 1.0, L: 26.0\n",
      "Episode R: 1.0, L: 21.0\n",
      "Episode R: 1.0, L: 16.0\n",
      "Episode R: 1.0, L: 12.0\n",
      "Episode R: 1.0, L: 15.0\n"
     ]
    }
   ],
   "source": [
    "agent.collect(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc574b-31fb-49b6-8c00-641b3beaa9ae",
   "metadata": {},
   "source": [
    "# PER testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515541ef-304f-4bdf-ba44-e2ba63b86dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../r2d2_algo')\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ee8c74-030d-4361-aa90-793923360689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import spaces\n",
    "import torch\n",
    "\n",
    "'''\n",
    "Class definnitions for replay buffer used in off-policy training\n",
    "'''\n",
    "\n",
    "class SequenceReplayBuffer:\n",
    "    def __init__(self, buffer_size, observation_space,\n",
    "                 action_space, hidden_state_size, sequence_length=1,\n",
    "                 burn_in_length=0, n_envs=1,\n",
    "                 alpha=0.6, beta=0.4, \n",
    "                 beta_increment=0.0001, max_priority=1.0):\n",
    "        '''\n",
    "        A replay buffer for R2D2 algorithm that when sampled, produces sequences of time steps.\n",
    "        Any index can be samples from, and burn_in_length steps before the index and sequence_length\n",
    "          steps after the index will be passed together\n",
    "        Note that there is one torch tensor per variable (observations, actions, rewards, dones, rnn_hxs)\n",
    "          and it will continuously be overwritten. Each tensor has length burn_in_length+buffer_size+sequence_length.\n",
    "          Think of it as having buffer_size, plus a chunk behind and ahead to handle burn in and sequence.\n",
    "          \n",
    "        self.pos keeps track of the next index to be written to. When it reaches the end (burn_in_length+buffer_size)\n",
    "          it loops back to the start (burn_in_length).\n",
    "          When it loops back, the burn_in_length chunk is copied from the end of the buffer.\n",
    "          As it covers the the first sequence_length worth of steps in the buffer, these get copied to the end\n",
    "            sequence_length chunk of the buffer\n",
    "        \n",
    "        buffer_size: number of steps to hold in buffer\n",
    "        sequence_length: number of steps in sequence\n",
    "        burn_in_length: number of steps before idx to be passed with sequence\n",
    "        \n",
    "        Priorities\n",
    "        '''\n",
    "        self.buffer_size = buffer_size\n",
    "        total_buffer_size = buffer_size + sequence_length + burn_in_length\n",
    "        self.n_envs = n_envs\n",
    "        self.sequence_length = sequence_length\n",
    "        self.burn_in_length = burn_in_length\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.beta_increment = beta_increment\n",
    "        self.max_priority = max_priority\n",
    "\n",
    "        self.td_priorities = np.zeros(total_buffer_size*n_envs) #holds individual td errors for priority calculations\n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < total_buffer_size*n_envs:\n",
    "            tree_capacity *= 2\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity) #trees hold actual priorities for faster updating and sampling\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        self.total_buffer_size = total_buffer_size\n",
    "        \n",
    "        action_shape = get_action_dim(action_space)\n",
    "        self.observations = np.zeros((total_buffer_size, n_envs, *observation_space.shape), dtype=observation_space.dtype)\n",
    "        self.actions = np.zeros((total_buffer_size, n_envs, action_shape), dtype=action_space.dtype)\n",
    "        self.rewards = np.zeros((total_buffer_size, n_envs), dtype=np.float32)\n",
    "        self.dones = np.zeros((total_buffer_size, n_envs), dtype=np.float32)\n",
    "        self.hidden_states = np.zeros((total_buffer_size, n_envs, hidden_state_size), dtype=np.float32)\n",
    "\n",
    "        \n",
    "        self.pos = burn_in_length\n",
    "        self.full = False\n",
    "        \n",
    "    def add(self, obs, next_obs, action, reward, done, hidden_state):\n",
    "        '''\n",
    "        Add to the buffer\n",
    "        '''\n",
    "        bil = self.burn_in_length\n",
    "        bs = self.buffer_size\n",
    "        sl = self.sequence_length\n",
    "\n",
    "        \n",
    "        self.observations[self.pos] = np.array(obs).copy()\n",
    "        self.observations[(self.pos + 1) % self.buffer_size] = np.array(next_obs).copy()\n",
    "        self.actions[self.pos] = np.array(action).copy()\n",
    "        self.rewards[self.pos] = np.array(reward).copy()\n",
    "        self.dones[self.pos] = np.array(done).copy()\n",
    "        self.hidden_states[self.pos] = np.array(hidden_state).copy()\n",
    "        \n",
    "        for i in range(self.n_envs):\n",
    "            self.td_priorities[self.pos + i*self.total_buffer_size] = self.max_priority\n",
    "            # 0 out probabilities for indexes that become invalid\n",
    "            self.sum_tree[self.pos + i*self.total_buffer_size] = 0.\n",
    "            self.sum_tree[self.pos + i*self.total_buffer_size + bil] = 0.\n",
    "        if (self.full and self.pos >= bil + sl) or (self.pos >= 2*bil + sl):\n",
    "            # only update steps in the past \n",
    "            #  there is a very slight chance this overwrites some priority that was set in \n",
    "            #  an update step but shouldn't make a huge difference\n",
    "            for i in range(self.n_envs):\n",
    "                self.sum_tree[self.pos + i*self.total_buffer_size - sl] = self.max_priority ** self.alpha\n",
    "                self.min_tree[self.pos + i*self.total_buffer_size - sl] = self.max_priority ** self.alpha\n",
    "        \n",
    "        \n",
    "        #Make copies to extra end portion\n",
    "        #Note that this makes it so that for a sequence_length period of time\n",
    "        #while we are filling up the end of the buffer, end steps cannot be used\n",
    "        if self.pos < bil + sl:\n",
    "            self.observations[self.pos+bs] = self.observations[self.pos].copy()\n",
    "            self.actions[self.pos+bs] = self.actions[self.pos].copy()\n",
    "            self.rewards[self.pos+bs] = self.rewards[self.pos].copy()\n",
    "            self.dones[self.pos+bs] = self.dones[self.pos].copy()\n",
    "            self.hidden_states[self.pos+bs] = self.hidden_states[self.pos].copy()\n",
    "            \n",
    "            # Copies of the end need to be made for td_priorities, but burn-in does not need\n",
    "            #  These priorities are not true priorities, just used to later calculate total td\n",
    "            #  for sequences. Hence they do not get copied to the sum_tree or min_tree\n",
    "            for i in range(self.n_envs):\n",
    "                self.td_priorities[self.pos+bs + i*self.total_buffer_size] = self.max_priority\n",
    "                # self.sum_tree[self.pos+bs + i*self.total_buffer_size] = self.max_priority ** self.alpha\n",
    "                # self.min_tree[self.pos+bs + i*self.total_buffer_size] = self.max_priority ** self.alpha\n",
    "\n",
    "            \n",
    "        self.pos += 1\n",
    "        if self.pos == self.buffer_size + self.burn_in_length:\n",
    "            self.pos = self.burn_in_length\n",
    "            self.full = True\n",
    "            \n",
    "            #Make copies to the burn_in portion\n",
    "            self.observations[:bil] = self.observations[bs:bs+bil].copy()\n",
    "            self.actions[:bil] = self.actions[bs:bs+bil].copy()\n",
    "            self.rewards[:bil] = self.rewards[bs:bs+bil].copy()\n",
    "            self.dones[:bil] = self.dones[bs:bs+bil].copy()\n",
    "            self.hidden_states[:bil] = self.hidden_states[bs:bs+bil].copy()\n",
    "\n",
    "            \n",
    "    def _sample_indices(self, num_sequences):\n",
    "        '''\n",
    "        Use sum tree to sample indices from priorities in segments\n",
    "        '''\n",
    "        t_indices = []\n",
    "        env_indices = []\n",
    "        p_total = self.sum_tree.sum()\n",
    "        segment = p_total / num_sequences\n",
    "        \n",
    "        # Check if stratified sampling will be valid based on number\n",
    "        #  of sequences asked for and fullness of storage        \n",
    "        for i in range(num_sequences):\n",
    "            found = False\n",
    "            sample_attempt_count = 0\n",
    "            valid_idxs = self.get_valid_idxs()\n",
    "            \n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            \n",
    "            while not found and sample_attempt_count < 50:\n",
    "                upperbound = random.uniform(a, b)\n",
    "                idx = self.sum_tree.retrieve(upperbound)\n",
    "                # print(idx)\n",
    "                t_index = idx % self.total_buffer_size\n",
    "                if valid_idxs[t_index]:\n",
    "                    found = True\n",
    "                sample_attempt_count += 1\n",
    "            \n",
    "            if sample_attempt_count >= 50:\n",
    "                # If this happens, either buffer is not being filled enough before\n",
    "                #  samples are being called for, or there is a bug\n",
    "                print('Warning: sample index failed to find valid index 50 times')\n",
    "                \n",
    "            t_indices.append(idx % self.total_buffer_size)\n",
    "            env_indices.append(idx // self.total_buffer_size)\n",
    "            \n",
    "        \n",
    "        return np.array(t_indices), np.array(env_indices)\n",
    "        \n",
    "        \n",
    "    def _calculate_weight(self, t_idx, env_idx):\n",
    "        '''Calculate the weight of the experience at idx.'''\n",
    "        # print(t_idx, env_idx)\n",
    "        \n",
    "        size = self.buffer_size if self.full else self.pos\n",
    "        size = size * self.n_envs\n",
    "        idx = t_idx + env_idx*self.total_buffer_size\n",
    "        \n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * size) ** (-self.beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * size) ** (-self.beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight\n",
    "        \n",
    "    def sample(self, num_sequences):\n",
    "        '''\n",
    "        Generate a sample of data to be trained with from the buffer\n",
    "        Note that we will actually generate a total training batch size of\n",
    "            num_sequences*self.sequence_length\n",
    "        and a total number of steps returned of\n",
    "            num_sequences*(self.sequence_length+self.burn_in_length).\n",
    "        It is up to the one calling sample to take into account how many\n",
    "        sequence samples it wants\n",
    "        '''\n",
    "        t_idxs, env_idxs = self._sample_indices(num_sequences)\n",
    "        start_idxs = t_idxs - self.burn_in_length\n",
    "        \n",
    "        window_idxs = np.arange(-self.burn_in_length, self.sequence_length)\n",
    "        window_length = len(window_idxs)\n",
    "        seq_idxs = t_idxs[:, np.newaxis] + window_idxs\n",
    "        seq_env_idxs = np.full((num_sequences, window_length), env_idxs[:, np.newaxis])\n",
    "        \n",
    "        # weights are [N, 1] tensor to be multiplied to each sequence batch generaated\n",
    "        weights = torch.Tensor([self._calculate_weight(t_idxs[i], env_idxs[i]) \\\n",
    "                                for i in range(num_sequences)]).reshape(-1, 1)\n",
    "\n",
    "        self.beta = min(1.0, self.beta + self.beta_increment)\n",
    "                \n",
    "        obs = torch.Tensor(self.observations[seq_idxs, seq_env_idxs])\n",
    "        next_obs = torch.Tensor(self.observations[seq_idxs+1, seq_env_idxs])\n",
    "        actions = torch.Tensor(self.actions[seq_idxs, seq_env_idxs])\n",
    "        rewards = torch.Tensor(self.rewards[seq_idxs, seq_env_idxs])\n",
    "        dones = torch.Tensor(self.dones[seq_idxs, seq_env_idxs])\n",
    "        next_dones = torch.Tensor(self.dones[seq_idxs+1, seq_env_idxs])\n",
    "        \n",
    "        hidden_states = torch.Tensor(self.hidden_states[start_idxs, env_idxs]).unsqueeze(0)\n",
    "        next_hidden_states = torch.Tensor(self.hidden_states[start_idxs+1, env_idxs]).unsqueeze(0)\n",
    "        \n",
    "        sample = {\n",
    "            'observations': obs,\n",
    "            'next_observations': next_obs,\n",
    "            'actions': actions,\n",
    "            'rewards': rewards,\n",
    "            'dones': dones,\n",
    "            'next_dones': next_dones,\n",
    "            'hidden_states': hidden_states,\n",
    "            'next_hidden_states': next_hidden_states,\n",
    "            'weights': weights,\n",
    "            't_idxs': t_idxs,\n",
    "            'seq_idxs': seq_idxs,\n",
    "            'env_idxs': env_idxs,\n",
    "        }\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def get_valid_idxs(self):\n",
    "        '''\n",
    "        Get array of valid indexes that can be sampled. Valid indexes are those with enough time steps\n",
    "        of data earlier to match burn_in_lenth and with enough time steps of data later to match\n",
    "        sequence_length.\n",
    "        \n",
    "        return a self.total_buffer_size (bil+buffer_size+seq_len) boolean array\n",
    "            that can be checked for truth by indexing directly\n",
    "        \n",
    "        Note: there is a slight bug here to be fixed in the future - there is a period where self.pos\n",
    "          loops back that the sequence_length post buffer is stale until overwritten fully \n",
    "        '''        \n",
    "        start = self.burn_in_length\n",
    "        end = self.burn_in_length + self.buffer_size\n",
    "        valid_idxs = np.full(self.total_buffer_size, False)\n",
    "        if self.full:\n",
    "            #Have enough terms ahead to be usable\n",
    "            valid_idxs[start:self.pos - self.sequence_length] = True\n",
    "            #Have enough terms behind to be usable\n",
    "            valid_idxs[self.pos + self.burn_in_length-1:end] = True\n",
    "        else:\n",
    "            #First burn_in_length steps are not valid because they haven't been copied\n",
    "            valid_idxs[start + self.burn_in_length:self.pos - self.sequence_length] = True\n",
    "        \n",
    "        return valid_idxs\n",
    "\n",
    "    def update_priorities(self, seq_idxs, env_idxs, priorities):\n",
    "        '''\n",
    "        seq_idxs: shape [N, seq_len]\n",
    "        env_idxs: shape [N,] for N batches\n",
    "        priorities: shape [N, seq_len]\n",
    "        '''\n",
    "        \n",
    "        valid_idxs = self.get_valid_idxs()\n",
    "        \n",
    "        n_batches = len(env_idxs)\n",
    "        for i in range(n_batches):\n",
    "            update_priority_idxs = seq_idxs[i] + env_idxs[i] * self.total_buffer_size\n",
    "            self.td_priorities[update_priority_idxs] = priorities[i]\n",
    "\n",
    "            for j in range(len(update_priority_idxs)):\n",
    "                start = seq_idxs[i, j] + env_idxs[i]*self.total_buffer_size\n",
    "\n",
    "                # check if the updated priority needs to be copied to buffer end segment\n",
    "                if seq_idxs[i, j] < self.burn_in_length + self.sequence_length:\n",
    "                    copy_idx = start + self.buffer_size\n",
    "                    self.td_priorities[copy_idx] = priorities[i, j]\n",
    "\n",
    "                if valid_idxs[seq_idxs[i, j]]:\n",
    "                    # next update priority based on future td_steps\n",
    "                    avg_td_priority = self.td_priorities[start:start+self.sequence_length].sum() / self.sequence_length\n",
    "                    self.sum_tree[start] = avg_td_priority ** self.alpha\n",
    "                    self.min_tree[start] = avg_td_priority ** self.alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def get_action_dim(action_space):\n",
    "    \"\"\"\n",
    "    Get the dimension of the action space.\n",
    "    \"\"\"\n",
    "    if isinstance(action_space, spaces.Box):\n",
    "        return int(np.prod(action_space.shape))\n",
    "    elif isinstance(action_space, spaces.Discrete):\n",
    "        # Action is an int\n",
    "        return 1\n",
    "    elif isinstance(action_space, spaces.MultiDiscrete):\n",
    "        # Number of discrete actions\n",
    "        return int(len(action_space.nvec))\n",
    "    elif isinstance(action_space, spaces.MultiBinary):\n",
    "        # Number of binary actions\n",
    "        assert isinstance(\n",
    "            action_space.n, int\n",
    "        ), \"Multi-dimensional MultiBinary action space is not supported. You can flatten it instead.\"\n",
    "        return int(action_space.n)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{action_space} action space is not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380f5892-b876-4bcd-a696-90472a72f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2D2Agent(nn.Module):\n",
    "    def __init__(self, batch_size=128, burn_in_length=4, sequence_length=8,\n",
    "                 gamma=0.99, tau=1., learning_rate=2.5e-4, hidden_size=64, adam_epsilon=1e-8,\n",
    "                 device=torch.device('cpu'), buffer_size=10_000, \n",
    "                 learning_starts=10_000, train_frequency=10, target_network_frequency=500,\n",
    "                 total_timesteps=30_000, start_e=1., end_e=0.05, exploration_fraction=0.5, \n",
    "                 alpha=0.6, beta=0.4,\n",
    "                 seed=None, n_envs=1, dummy_env=True,\n",
    "                 env_id='CartPole-v1', env_kwargs={},\n",
    "                 verbose=0, q_network=None,  deterministic=False, env=None,\n",
    "                 writer=None, handle_target_network=True, use_per=True):\n",
    "        \"\"\"\n",
    "        R2D2 setup following same parameters as args.py has\n",
    "        verbose: Level of verbosity of print statements\n",
    "            1: print episode lengths and returns means every 2000 steps\n",
    "            2: print every episode length and return\n",
    "        q_network: Mostly for use of evaluation with a saved q_network\n",
    "          optionally pass in a q_network to use manually\n",
    "        deterministic: If True, manually set epsilon to 0 for every act() call\n",
    "        env: Also option to manually pass in an environment\n",
    "        n_envs: option to make multiple envs and have q_network generate multiple\n",
    "        dummy_env: whether to use DummyVecEnv as opposed to SubprocVecEnv for testing\n",
    "        writer: option to pass a tensorboard SummaryWriter object\n",
    "        handle_target_network: whether this class is in charge of updating the target network\n",
    "            params\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.buffer_size = buffer_size\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.learning_starts = learning_starts\n",
    "        self.train_frequency = train_frequency\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.use_per = use_per\n",
    "        self.adam_epsilon = adam_epsilon\n",
    "        self.target_network_frequency = target_network_frequency\n",
    "        self.handle_target_network = handle_target_network\n",
    "        self.device = device\n",
    "\n",
    "        self.start_e = start_e\n",
    "        self.end_e = end_e\n",
    "        self.exploration_fraction = exploration_fraction\n",
    "\n",
    "        self.burn_in_length = burn_in_length\n",
    "        self.sequence_length = sequence_length\n",
    "        self.batch_size = batch_size\n",
    "        self.n_envs = n_envs\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.seed = seed\n",
    "        self.deterministic = deterministic\n",
    "        if env == None:\n",
    "            # self.env = gym.make(env_id, **env_kwargs)\n",
    "            self.env = make_vec_envs(env_id, n_envs, env_kwargs=env_kwargs,\n",
    "                                     dummy=dummy_env)\n",
    "        else:\n",
    "            self.env = env\n",
    "        \n",
    "        \n",
    "        if q_network == None:\n",
    "            self.q_network = RNNQNetwork(self.env, hidden_size).to(device)\n",
    "        else:\n",
    "            self.q_network = q_network\n",
    "        self.target_network = RNNQNetwork(self.env, hidden_size).to(device)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "        \n",
    "        self.rb = SequenceReplayBuffer(buffer_size, self.env.observation_space, self.env.action_space,\n",
    "                                hidden_size, sequence_length=sequence_length, \n",
    "                                burn_in_length=burn_in_length, n_envs=n_envs,\n",
    "                                alpha=alpha, beta=beta)\n",
    "\n",
    "        \n",
    "        self.global_step = 0\n",
    "        self.global_update_step = 0\n",
    "        self.rnn_hxs = self.q_network.get_rnn_hxs(self.n_envs)\n",
    "        self.obs = self.env.reset()\n",
    "        self.masks = torch.zeros((self.n_envs, 1), dtype=torch.float32)\n",
    "        \n",
    "        self.cur_episode_t = np.zeros(self.n_envs)\n",
    "        self.cur_episode_r = np.zeros(self.n_envs)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.writer = writer\n",
    "        self.start_time = time.time()\n",
    "        self.lengths = []\n",
    "        self.returns = []\n",
    "        \n",
    "    \n",
    "    def act(self, obs, rnn_hxs, use_epsilon=True, masks=None):\n",
    "        \"\"\"Compute q values and sample policy. If epsilon is True,\n",
    "        perform randomo action with probability based on current global timestep\n",
    "        \n",
    "        masks: tensor of shape (N, 1) which has entries 0.0 when done\n",
    "            and 1.0 when not done, indicating when rnn_hxs should be reset\n",
    "            Used for vectorized environments\n",
    "        \"\"\"            \n",
    "        epsilon = self.get_epsilon(use_epsilon)\n",
    "        \n",
    "        obs_tensor = torch.Tensor(obs).to(self.device)\n",
    "        if obs_tensor.dim() < rnn_hxs.dim():\n",
    "            # We have an observation from the environment but need to unsqueeze\n",
    "            #  to tell the GRU that this is an observation of time length 1\n",
    "            # If it is batched (dim == 2), then we add an axis in the middle\n",
    "            #  otherwise add it to the start\n",
    "            if obs_tensor.dim() == 1:\n",
    "                obs_tensor = obs_tensor.unsqueeze(0)\n",
    "                action_dim = 1\n",
    "            elif obs_tensor.dim() == 2:\n",
    "                obs_tensor = obs_tensor.unsqueeze(1)\n",
    "                action_dim = 2\n",
    "        \n",
    "        else:\n",
    "            if obs_tensor.dim() == 2:\n",
    "                action_dim = 1\n",
    "            elif obs_tensor.dim() == 3:\n",
    "                action_dim = 2  \n",
    "            \n",
    "        q_values, gru_out, next_rnn_hxs = self.q_network(obs_tensor, rnn_hxs, masks=masks)\n",
    "                \n",
    "        \n",
    "        # action = np.array([[q_values.argmax()]])\n",
    "        action = q_values.argmax(dim=action_dim).numpy()\n",
    "        if use_epsilon:\n",
    "            if len(action.shape) == 1:\n",
    "                for i in range(action.shape[0]):\n",
    "                    if random.random() < epsilon:\n",
    "                        action[i] = self.env.action_space.sample()\n",
    "            elif len(action.shape) == 2:\n",
    "                for i in range(action.shape[0]):\n",
    "                    for j in range(action.shape[1]):\n",
    "                        if random.random() < epsilon:\n",
    "                            action[i, j] = self.env.action_space.sample()\n",
    "            \n",
    "        if len(action.shape) == 1:\n",
    "            action = action[np.newaxis, :]\n",
    "\n",
    "        return action, q_values, next_rnn_hxs\n",
    "                \n",
    "        \n",
    "    def collect(self, num_steps):\n",
    "        \"\"\"Perform policy for n steps and add to memory buffer\n",
    "        \n",
    "        Note that we will add a total of num_steps * self.n_envs to the buffer\"\"\"\n",
    "        env = self.env\n",
    "        \n",
    "        for t in range(num_steps):\n",
    "            action, q_values, next_rnn_hxs = self.act(self.obs, self.rnn_hxs, masks=self.masks)\n",
    "            next_obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            self.cur_episode_r += reward\n",
    "            self.cur_episode_t += 1\n",
    "            \n",
    "            # if done:\n",
    "            #     next_obs = env.reset()\n",
    "            #     next_rnn_hxs = self.q_network.get_rnn_hxs()\n",
    "                \n",
    "            #     if self.verbose >= 1:\n",
    "            #         print(f'Episode R: {self.cur_episode_r}, L: {self.cur_episode_t}')\n",
    "                \n",
    "            #     self.cur_episode_t = 0\n",
    "            #     self.cur_episode_r = 0\n",
    "\n",
    "            # Masks are used to reset hidden state when vectorized environmnts give dones\n",
    "            self.masks = torch.FloatTensor(\n",
    "                [[0.0] if done_ else [1.0] for done_ in done])\n",
    "\n",
    "            for i, done_ in enumerate(done):\n",
    "                if done_:\n",
    "                    if self.verbose == 2:\n",
    "                        print(f'Episode R: {self.cur_episode_r[i]}, L: {self.cur_episode_t[i]}')\n",
    "                        \n",
    "                    if self.writer is not None:\n",
    "                        self.writer.add_scalar('charts/episodic_return', self.cur_episode_r[i], self.global_step)\n",
    "                        self.writer.add_scalar('charts/episodic_length', self.cur_episode_t[i], self.global_step)\n",
    "                        self.writer.add_scalar('charts/epsilon', self.get_epsilon(), self.global_step)\n",
    "\n",
    "                    self.lengths.append(self.cur_episode_t[i])\n",
    "                    self.returns.append(self.cur_episode_r[i])\n",
    "                    \n",
    "                    self.cur_episode_r[i] = 0\n",
    "                    self.cur_episode_t[i] = 0\n",
    "                    \n",
    "\n",
    "            self.rb.add(self.obs, next_obs, action, reward, done, self.rnn_hxs.detach())\n",
    "            \n",
    "            self.obs = next_obs\n",
    "            self.rnn_hxs = next_rnn_hxs\n",
    "            \n",
    "            self.global_step += self.n_envs\n",
    "            \n",
    "            if self.handle_target_network and self.global_step > self.learning_starts and \\\n",
    "                self.global_step % self.target_network_frequency < self.n_envs:\n",
    "                for target_network_param, q_network_param in zip(self.target_network.parameters(), self.q_network.parameters()):\n",
    "                    target_network_param.data.copy_(\n",
    "                        self.tau * q_network_param.data + (1 - self.tau) * target_network_param.data\n",
    "                    )\n",
    "            \n",
    "            if self.global_step % 2000 < self.n_envs:\n",
    "                if self.verbose == 1:\n",
    "                    print(f'Mean episode length {np.mean(self.lengths)}, mean return {np.mean(self.returns)}')\n",
    "                self.lengths = []\n",
    "                self.returns = []\n",
    "\n",
    "                \n",
    "            \n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"Sample from buffer and perform Q-learning\"\"\"\n",
    "        \n",
    "        sample = self.rb.sample(self.batch_size//self.sequence_length)\n",
    "        states = sample['observations']\n",
    "        next_states = sample['next_observations']\n",
    "        hidden_states = sample['hidden_states']\n",
    "        next_hidden_states = sample['next_hidden_states']\n",
    "        actions = sample['actions']\n",
    "        rewards = sample['rewards']\n",
    "        dones = sample['dones']\n",
    "        next_dones = sample['next_dones']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            target_q, _, _ = self.target_network(next_states, next_hidden_states, next_dones)\n",
    "            target_max, _ = target_q.max(dim=2)\n",
    "            td_target = rewards + self.gamma * target_max * (1 - dones)\n",
    "        old_q, _, _ = self.q_network(states, hidden_states, dones)\n",
    "        old_val = old_q.gather(2, actions.long()).squeeze()\n",
    "\n",
    "        # loss = F.mse_loss(td_target[:, self.burn_in_length:], old_val[:, self.burn_in_length:])\n",
    "        weights = sample['weights']\n",
    "        elementwise_loss = F.smooth_l1_loss(td_target[:, self.burn_in_length:],\n",
    "                                            old_val[:, self.burn_in_length:], reduction='none')\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "                \n",
    "        if self.writer is not None and self.global_update_step % 10 == 0:\n",
    "            self.writer.add_scalar('losses/td_loss', loss, self.global_step)\n",
    "            self.writer.add_scalar('losses/q_values', old_val.mean().item(), self.global_step)\n",
    "            sps = int(self.global_step / (time.time() - self.start_time))\n",
    "            # print('SPS:', int(sps))\n",
    "            self.writer.add_scalar('charts/SPS', sps, self.global_step)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        td_priorities = elementwise_loss.detach().cpu().numpy() + 1e-6\n",
    "        self.rb.update_priorities(sample['seq_idxs'][:, self.burn_in_length:],\n",
    "                                  sample['env_idxs'], td_priorities)\n",
    "        \n",
    "        self.global_update_step += 1\n",
    "    \n",
    "\n",
    "    def train(self, n_updates):\n",
    "        if self.global_step < self.learning_starts:\n",
    "            self.collect((self.learning_starts - self.global_step) // self.n_envs + 1)\n",
    "        \n",
    "        for i in range(n_updates):\n",
    "            self.collect(self.train_frequency)\n",
    "            self.update()\n",
    "\n",
    "\n",
    "    def get_rnn_hxs(self):\n",
    "        return self.q_network.get_rnn_hxs(self.n_envs)\n",
    "    \n",
    "    def get_epsilon(self, use_epsilon=True):\n",
    "        if use_epsilon:\n",
    "            epsilon = linear_schedule(self.start_e, self.end_e, \n",
    "                        self.exploration_fraction*self.total_timesteps,\n",
    "                        self.global_step)\n",
    "        else:\n",
    "            epsilon = 0\n",
    "            \n",
    "        return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e347cd32-da0c-428e-bba7-5588e036a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "        'num_objects': 0, 'rew_structure': 'goal',\n",
    "        'task_structure': 2, 'wall_colors': 4,\n",
    "        'num_rays': 12, 'fov': 1\n",
    "}\n",
    "\n",
    "agent = R2D2Agent(env_id='NavEnv-v0', env_kwargs=env_kwargs,\n",
    "                 verbose=1, buffer_size=5000, alpha=0.6, batch_size=256,\n",
    "                 burn_in_length=8, n_envs=4, dummy_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b367d6e0-efd0-4fcf-a10c-7d9d5599102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 177.85714285714286, mean return 0.14285714285714285\n",
      "Mean episode length 202.0, mean return 0.0\n"
     ]
    }
   ],
   "source": [
    "agent.collect(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "0955941e-a8a3-47f6-a3d1-71a7dbbaa6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "820 ms ± 28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.collect(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713496bd-9c4d-4404-b780-225000767141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode length 187.15384615384616, mean return 0.07692307692307693\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 187.23076923076923, mean return 0.07692307692307693\n",
      "4.53 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.collect(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37601078-533c-4a5a-af7f-113ec5e1650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "3.7 ms ± 53.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.collect(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "7a33ae4b-f84c-4b5d-918c-81e0c1d2df5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "Mean episode length 202.0, mean return 0.0\n",
      "2.02 ms ± 82 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.collect(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1629669b-7c46-4a41-a31d-1f3182fe1469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.9 ms ± 1.08 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "cbc807ed-2c31-4506-ae5d-acbf5d9deac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.1 ms ± 2.07 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402c6b64-b753-4e26-81b5-1aefb4985816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1 ms ± 918 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18303cc9-db1d-4959-8320-9943b22eb353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826 µs ± 12.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sample = agent.rb.sample(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbfa8225-6f19-42ef-89e6-6b4928adb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = agent.rb.sample(256//8)\n",
    "states = sample['observations']\n",
    "next_states = sample['next_observations']\n",
    "hidden_states = sample['hidden_states']\n",
    "next_hidden_states = sample['next_hidden_states']\n",
    "actions = sample['actions']\n",
    "rewards = sample['rewards']\n",
    "dones = sample['dones']\n",
    "next_dones = sample['next_dones']\n",
    "\n",
    "with torch.no_grad():\n",
    "    target_q, _, _ = agent.target_network(next_states, next_hidden_states, next_dones)\n",
    "    target_max, _ = target_q.max(dim=2)\n",
    "    td_target = rewards + agent.gamma * target_max * (1 - dones)\n",
    "old_q, _, _ = agent.q_network(states, hidden_states, dones)\n",
    "old_val = old_q.gather(2, actions.long()).squeeze()\n",
    "\n",
    "old_loss = F.mse_loss(td_target[:, agent.burn_in_length:], old_val[:, agent.burn_in_length:])\n",
    "weights = sample['weights']\n",
    "elementwise_loss = F.smooth_l1_loss(td_target[:, agent.burn_in_length:],\n",
    "                                    old_val[:, agent.burn_in_length:], reduction='none')\n",
    "loss = torch.mean(elementwise_loss * weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df01e18d-7c99-4bc9-9e20-d6ab3a6f0480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.1248],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204],\n",
       "        [0.0204]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bb18221-2737-45bb-90ee-22c8d75372e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.42 ms ± 254 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    target_q, _, _ = agent.target_network(next_states, next_hidden_states, next_dones)\n",
    "    target_max, _ = target_q.max(dim=2)\n",
    "    td_target = rewards + agent.gamma * target_max * (1 - dones)\n",
    "old_q, _, _ = agent.q_network(states, hidden_states, dones)\n",
    "old_val = old_q.gather(2, actions.long()).squeeze()\n",
    "\n",
    "old_loss = F.mse_loss(td_target[:, agent.burn_in_length:], old_val[:, agent.burn_in_length:])\n",
    "weights = sample['weights']\n",
    "elementwise_loss = F.smooth_l1_loss(td_target[:, agent.burn_in_length:],\n",
    "                                    old_val[:, agent.burn_in_length:], reduction='none')\n",
    "loss = torch.mean(elementwise_loss * weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1bf82f6-a358-46ff-9930-e88223fd8d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.6 ms ± 401 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    target_q, _, _ = agent.target_network(next_states, next_hidden_states, next_dones)\n",
    "    target_max, _ = target_q.max(dim=2)\n",
    "    td_target = rewards + agent.gamma * target_max * (1 - dones)\n",
    "old_q, _, _ = agent.q_network(states, hidden_states, dones)\n",
    "old_val = old_q.gather(2, actions.long()).squeeze()\n",
    "\n",
    "old_loss = F.mse_loss(td_target[:, agent.burn_in_length:], old_val[:, agent.burn_in_length:])\n",
    "weights = sample['weights']\n",
    "elementwise_loss = F.smooth_l1_loss(td_target[:, agent.burn_in_length:],\n",
    "                                    old_val[:, agent.burn_in_length:], reduction='none')\n",
    "loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "agent.optimizer.zero_grad()\n",
    "loss.backward()\n",
    "agent.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62a62f25-2307-40e8-870d-dd9fdd6cbade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms ± 258 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "td_priorities = elementwise_loss.detach().cpu().numpy() + 1e-6\n",
    "agent.rb.update_priorities(sample['seq_idxs'][:, agent.burn_in_length:],\n",
    "                          sample['env_idxs'], td_priorities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98ef7e66-87cb-4a68-81c9-125cc73f095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_idxs = sample['seq_idxs'][:, agent.burn_in_length:]\n",
    "env_idxs = sample['env_idxs']\n",
    "priorities = td_priorities\n",
    "rb = agent.rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25bcef4-1e69-431a-aa45-fae9e22f3981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 µs ± 1.63 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * rb.total_buffer_size\n",
    "    rb.td_priorities[update_priority_idxs] = priorities[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2da1adb0-a786-4152-86a3-6dd1f65ddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 µs ± 28.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * rb.total_buffer_size\n",
    "    rb.td_priorities[update_priority_idxs] = priorities[i]\n",
    "\n",
    "    for j in range(len(update_priority_idxs)):\n",
    "        start = seq_idxs[i, j] + env_idxs[i]*rb.total_buffer_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92d7abab-fb30-49e6-810f-be4312a0f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1 ms ± 186 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "valid_idxs = rb.get_valid_idxs()\n",
    "\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * rb.total_buffer_size\n",
    "    rb.td_priorities[update_priority_idxs] = priorities[i]\n",
    "\n",
    "    for j in range(len(update_priority_idxs)):\n",
    "        start = seq_idxs[i, j] + env_idxs[i]*rb.total_buffer_size\n",
    "        \n",
    "        # check if the updated priority needs to be copied to buffer end segment\n",
    "        if seq_idxs[i, j] < rb.burn_in_length + rb.sequence_length:\n",
    "            copy_idx = start + rb.buffer_size\n",
    "            rb.td_priorities[copy_idx] = priorities[i, j]\n",
    "\n",
    "        if valid_idxs[seq_idxs[i, j]]:\n",
    "            # next update priority based on future td_steps\n",
    "            avg_td_priority = rb.td_priorities[start:start+rb.sequence_length].sum() / rb.sequence_length\n",
    "            rb.sum_tree[start] = avg_td_priority ** rb.alpha\n",
    "            rb.min_tree[start] = avg_td_priority ** rb.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d5dc188-483b-466e-9c64-ced94491b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 ms ± 219 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "valid_idxs = rb.get_valid_idxs()\n",
    "\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * rb.total_buffer_size\n",
    "    rb.td_priorities[update_priority_idxs] = priorities[i]\n",
    "\n",
    "\n",
    "for i, j in zip(seq_idxs):\n",
    "    start = seq_idxs[i, j] + env_idxs[i]*rb.total_buffer_size\n",
    "\n",
    "    avg_td_priority = rb.td_priorities[start:start+rb.sequence_length].sum() / rb.sequence_length\n",
    "    rb.sum_tree[start] = avg_td_priority ** rb.alpha\n",
    "    rb.min_tree[start] = avg_td_priority ** rb.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8c7687a-8dbb-44f6-9205-36799f8d1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = seq_idxs + env_idxs.reshape(-1, 1) * rb.total_buffer_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ada1e035-1bae-4fac-ad07-e6e7d8a35346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.82 ms ± 45.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "mesh = np.meshgrid(range(starts.shape[0]), range(starts.shape[1]))\n",
    "for i, j in zip(mesh[0].reshape(-1), mesh[1].reshape(-1)):\n",
    "    rb.sum_tree[starts[i, j]] = avg_td_priority ** rb.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "464a3319-78ed-4426-91ce-69e7224ec95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6 µs ± 160 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rb.sum_tree[starts[i, j]] = avg_td_priority ** rb.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fad1cd5a-4ee1-4c2b-b752-434d60d8c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rb.sum_tree.tree[cap:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "28a98f24-6fa9-440f-94e2-34ccb800e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.03 ms ± 94 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ee8786b-7252-4770-9786-f9e9055f2aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.77 ms ± 527 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "p_cumsum = np.cumsum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "21a92a38-8972-4ed2-8ff7-6c662b28eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.99 ms ± 55.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "p_cum = np.cumsum(p)\n",
    "p_total = p_cum[-1]\n",
    "rands = np.random.random(5) * p_total\n",
    "idxs = (p_cum.reshape(-1, 1) > rands).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "24246d9b-0100-4c55-84f2-954028c625b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cum = np.cumsum(p)\n",
    "p_total = p_cum[-1]\n",
    "rands = np.random.random(5) * p_total\n",
    "idxs = (p_cum.reshape(-1, 1) > rands).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3bff71cc-1b3d-4abe-a4eb-0c6ff892daef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2687, 2091, 1022, 3680, 3614], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs % rb.total_buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ffd3bc9d-e37e-49d0-a306-02be3489592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs // rb.total_buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8a5ae1d1-ab21-40b4-827f-a5d0bfecc5a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceReplayBuffer' object has no attribute 'buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [131]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__len__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mSequenceReplayBuffer.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequenceReplayBuffer' object has no attribute 'buffer'"
     ]
    }
   ],
   "source": [
    "rb.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "010019c6-e96b-4c0e-9eb1-60344fe545e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 ns ± 2.51 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "min(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7256193e-efd2-4d18-b5ce-f191e8fbd5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(range(starts.shape[0]), range(starts.shape[1])):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f36dd7a8-b191-443c-948a-e7f467ef8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "valid_idxs = rb.get_valid_idxs()\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * rb.total_buffer_size\n",
    "    rb.td_priorities[update_priority_idxs] = priorities[i]\n",
    "\n",
    "    for j in range(len(update_priority_idxs)):\n",
    "        start = seq_idxs[i, j] + env_idxs[i]*rb.total_buffer_size\n",
    "        \n",
    "        # check if the updated priority needs to be copied to buffer end segment\n",
    "        if seq_idxs[i, j] < rb.burn_in_length + rb.sequence_length:\n",
    "            copy_idx = start + rb.buffer_size\n",
    "            rb.td_priorities[copy_idx] = priorities[i, j]\n",
    "\n",
    "        if valid_idxs[seq_idxs[i, j]]:\n",
    "            count += 1\n",
    "            # next update priority based on future td_steps\n",
    "            avg_td_priority = rb.td_priorities[start:start+rb.sequence_length].sum() / rb.sequence_length\n",
    "            rb.sum_tree[start] = avg_td_priority ** rb.alpha\n",
    "            rb.min_tree[start] = avg_td_priority ** rb.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25e60021-d62c-47e3-a2c5-f88ab9b38c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a50d7c-84ed-44f1-b8fb-57a9951d3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = rb.sum_tree.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8f8b851-6578-46fc-aebe-59cac8980fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.6 ns ± 0.826 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e14679cb-7008-4fbe-b018-c120f6a35c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 ns ± 6.35 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "avg_td_priority ** rb.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "687fb184-7a64-4a48-9cce-d41ee873505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.71 µs ± 198 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rb.sum_tree[5] = avg_td_priority ** rb.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0157c7f-3825-45de-a344-fd1691da45f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ns ± 1.47 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rb.sum_tree.tree[cap+5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04421e41-d763-402c-8413-4d135c5a1656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 µs ± 20.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * rb.total_buffer_size\n",
    "    rb.td_priorities[update_priority_idxs] = priorities[i]\n",
    "\n",
    "    for j in range(len(update_priority_idxs)):\n",
    "        start = seq_idxs[i, j] + env_idxs[i]*rb.total_buffer_size\n",
    "        \n",
    "        # check if the updated priority needs to be copied to buffer end segment\n",
    "        if seq_idxs[i, j] < rb.burn_in_length + rb.sequence_length:\n",
    "            copy_idx = start + rb.buffer_size\n",
    "            rb.td_priorities[copy_idx] = priorities[i, j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b7ebb13-2a5f-45c4-89ce-40c0f0f5bf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19155, 19156, 19157, 19158, 19159, 19160, 19161, 19162])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_priority_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2099ba7a-587f-4658-9e32-ab544ac65c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.22 µs ± 137 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "agent.rb.sum_tree[5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d79abb-7e52-4540-bbde-09a881447e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 24])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "1d56ccdc-454a-43fd-a02a-37b1736ebe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd = dones[-1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1ad3d304-553a-4d8e-a100-ff7d1ecb496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_seq_idxs = sample['seq_idxs'][:, agent.burn_in_length:]\n",
    "seq_idxs = update_seq_idxs\n",
    "\n",
    "priorities = elementwise_loss.detach().numpy()\n",
    "env_idxs = sample['env_idxs']\n",
    "\n",
    "\n",
    "n_batches = len(env_idxs)\n",
    "for i in range(n_batches):\n",
    "    update_priority_idxs = seq_idxs[i] + env_idxs[i] * agent.rb.total_buffer_size\n",
    "    agent.rb.td_priorities[update_priority_idxs] = priorities[i]\n",
    "    \n",
    "    for j in range(len(update_priority_idxs)):\n",
    "        start = seq_idxs[i, j] + env_idxs[i]*agent.rb.total_buffer_size\n",
    "        \n",
    "        # check if the updated priority needs to be copied to buffer end segment\n",
    "        if seq_idxs[i, j] < agent.rb.burn_in_length + agent.rb.sequence_length:\n",
    "            copy_idx = start + agent.rb.buffer_size\n",
    "            agent.rb.td_priorities[copy_idx] = priorities[i, j]\n",
    "        # next update priority based on future td_steps\n",
    "        avg_td_priority = agent.rb.td_priorities[start:start+agent.rb.sequence_length].sum() / agent.rb.sequence_length\n",
    "        agent.rb.sum_tree[start] = avg_td_priority ** agent.rb.alpha\n",
    "        agent.rb.min_tree[start] = avg_td_priority ** agent.rb.alpha\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
